{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Adversarial-Training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6RCnATr72e2I"},"source":["# Adversarial Training\n","\n","Adversarial Training of Robust CNN"]},{"cell_type":"markdown","metadata":{"id":"0zHOqSU22tyA"},"source":["## Imports"]},{"cell_type":"markdown","metadata":{"id":"_18eYchd3arh"},"source":["### GPU Information\n","\n","The following GPU is used while Training the Model. Google Colab is used for Training so the GPU might change while running it later.\n","\n","**GPU-Specifications:**\n","*   Name: Tesla P100-PCIE\n","*   GPU Memory: 16280MiB"]},{"cell_type":"code","metadata":{"id":"RcZrIK8q3oc1"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWl0a4nz2vzp"},"source":["### Importing Data\n","Files are uploaded in Google Drive. Notebook is connected to Google Drive"]},{"cell_type":"code","metadata":{"id":"aXIKwud723ro"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My\\ Drive/Modulation-Classification/RadioML-Dataset/Data/CW-Attack"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dg3UTQlZ4BTC"},"source":["### Importing Libraries\n","\n","Cleverhans is used for generating Adversarial Examples."]},{"cell_type":"code","metadata":{"id":"kgy04Rrz4GIR"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.image as pimg\n","import seaborn as sns\n","import scipy.io\n","import os\n","import pickle\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix,accuracy_score\n","\n","# Tensorflow Libraries\n","!pip3 install tensorflow==2.2.0\n","!pip3 install keras-tuner==1.0.2\n","import tensorflow as tf\n","#tf.compat.v1.disable_eager_execution()\n","from tensorflow.keras.layers import Dense, Flatten, ReLU, Conv2D, Input, MaxPooling2D, BatchNormalization, AveragePooling2D, Reshape, ZeroPadding2D, Dropout, Activation, Permute, Concatenate\n","from tensorflow.keras.models import Model,Sequential\n","\n","# ART Libraries\n","\"\"\"\n","!pip3 install adversarial-robustness-toolbox[tensorflow]\n","from art.attacks.evasion import CarliniL2Method\n","from art.estimators.classification import KerasClassifier\n","\"\"\"\n","\n","# Cleverhans Libraries\n","!pip3 install cleverhans\n","from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n","from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n","from cleverhans.tf2.attacks.carlini_wagner_l2 import CarliniWagnerL2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wHoasUAz9Uj1"},"source":["### Importing Datasets"]},{"cell_type":"markdown","metadata":{"id":"sRj6ENUcuAAM"},"source":["Importing Data"]},{"cell_type":"code","metadata":{"id":"CW_1HWfw9YZP"},"source":["# Loading Training Data\n","Clean_X_Train = np.load(\"../Clean-Data/Clean_X_Train.npy\")\n","Clean_y_Train = np.load(\"../Clean-Data/Clean_y_Train.npy\")\n","\n","# Loading Validation Data\n","f = open(\"../Clean-Data/Clean_X_Valid.pkl\",\"rb\")\n","Clean_X_Valid = pickle.load(f)\n","\n","f = open(\"../Clean-Data/Clean_y_Valid.pkl\",\"rb\")\n","Clean_y_Valid = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p55uSk2-r6Hj"},"source":["Processing Data"]},{"cell_type":"code","metadata":{"id":"5J-OvL3HsAL5"},"source":["Clean_X_Train = np.expand_dims(np.transpose(Clean_X_Train, (0,2,1)),axis=-1)\n","\n","for snr in Clean_X_Valid.keys():\n","    Clean_X_Valid[snr] = np.expand_dims(np.transpose(Clean_X_Valid[snr], (0,2,1)),axis=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v4hEs2of4dic"},"source":["## Designing Attack\n","\n","**CW Attack**\n","```\n","CW = CarliniWagnerL2(\n","            model_fn = Robust_CNN,\n","            y = np.repeat(Target_Encoding.reshape(-1,len(Target_Encoding)),Size,axis=0),\n","            targeted = True,\n","            batch_size = Size,\n","            clip_max = Max,\n","            clip_min = Min,\n","            max_iterations = nb_Iterations,\n","            learning_rate = Learning_Rate\n","        )\n","\n","X_Batch_Adv = CW.attack(X_Batch)\n","```"]},{"cell_type":"markdown","metadata":{"id":"C336Lsq52nNi"},"source":["Modulation Schemes"]},{"cell_type":"code","metadata":{"id":"cVy3soOd2rwm"},"source":["f = open(\"../Dataset/ModulationMap.pkl\", \"rb\")\n","ModulationMap = pickle.load(f)\n","ModulationMap = dict((v,k) for k,v in ModulationMap.items())\n","ModulationMap"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NJBkoyQ40jfB"},"source":["Attack Settings\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Y3761sV10pKL"},"source":["# 8PSK is considered as target\n","TargetLabel = '8PSK'\n","Target = ModulationMap[TargetLabel]\n","Target_Encoding = np.zeros((11,))\n","Target_Encoding[Target] = 1\n","print (\"Target Encoding:\", Target_Encoding)\n","\n","# Parameters of CW\n","nb_Iterations = 100\n","Confidence = 0.9\n","Batch_Size = 1024\n","Learning_Rate = 0.001\n","Max = np.max(Clean_X_Train)\n","Min = np.min(Clean_X_Train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"77Qll5Fc04xZ"},"source":["## Model\n","\n","Robust_CNN Model is designed and Adversally Trained and Examples generated from it are used to perform Transfer-Based Attack"]},{"cell_type":"markdown","metadata":{"id":"U5Cvg2N49OEd"},"source":["### Creating Robust_CNN\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"o8m32N_L1iyx"},"source":["tf.keras.backend.clear_session()\n","\n","Inp = Input(shape=(128,2,1))\n","\n","x = Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='glorot_uniform')(Inp)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D(pool_size=(2,1), padding='valid')(x)\n","x = Dropout(0.3)(x)\n","\n","x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='glorot_uniform')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D(pool_size=(2,1), padding='valid')(x)\n","x = Dropout(0.3)(x)\n","\n","x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='glorot_uniform')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D(pool_size=(2,1), padding='valid')(x)\n","x = Dropout(0.3)(x)\n","\n","x = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', kernel_initializer='glorot_uniform')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D(pool_size=(2,1), padding='valid')(x)\n","x = Dropout(0.3)(x)\n","\n","x = Flatten()(x)\n","x = Dense(128, activation='relu', kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","Out = Dense(11,activation='softmax', kernel_initializer='he_normal')(x)\n","\n","Robust_CNN = Model(Inp,Out)\n","Robust_CNN.summary()\n","tf.keras.utils.plot_model(Robust_CNN, to_file='Robust_CNN.png', show_shapes=True,show_layer_names=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vjnr-98u9xIx"},"source":["### Training the Model"]},{"cell_type":"markdown","metadata":{"id":"qCVSj1M9-Jl-"},"source":["Model Training Settings"]},{"cell_type":"code","metadata":{"id":"THmDT5eo90VM"},"source":["LossFunction = tf.losses.CategoricalCrossentropy()\n","AccuracyFunction = tf.keras.metrics.Accuracy()\n","Optimizer = tf.optimizers.Adam()\n","Epochs = 250\n","Batch_Size = 3072\n","N = Clean_X_Train.shape[0]\n","Steps = int(np.ceil(N/Batch_Size))\n","\n","Robust_CNN.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n","History = {\"Loss\": np.zeros(Epochs), \"Accuracy\": np.zeros(Epochs)}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FkmW63t5_Tzl"},"source":["Train Step"]},{"cell_type":"code","metadata":{"id":"HSxf-udj_dZl"},"source":["@tf.function\n","def train_step(x,y):\n","    with tf.GradientTape() as tape:\n","        # Predict\n","        y_pred = Robust_CNN(x, training=True)\n","\n","        # Loss\n","        loss = LossFunction(y, y_pred)\n","\n","    # Back Propagation\n","    gradients = tape.gradient(loss, Robust_CNN.trainable_variables)\n","    Optimizer.apply_gradients(zip(gradients, Robust_CNN.trainable_variables))\n","\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GrQ__4aIVNs2"},"source":["Training Dataset"]},{"cell_type":"code","metadata":{"id":"bldX9YT1VPvz"},"source":["Adv_X = np.copy(Clean_X_Train)\n","Adv_y = np.copy(Clean_y_Train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zBeKgLE9AIqK"},"source":["Adversarial Training"]},{"cell_type":"code","metadata":{"id":"5sqLIp23AKeK"},"source":["for epoch in range(Epochs):\n","    print (\"Epoch-\" + str(epoch) + \":\")\n","\n","    # Shuffling Data\n","    ShuffleIndex = np.random.choice(N, size=N, replace=False)\n","    Adv_X = np.copy(Clean_X_Train)\n","    \n","    # Adversarial Samples\n","    for step in range(Steps):\n","        i = step*Batch_Size\n","        j = min((step + 1)*Batch_Size, N)\n","        Indices = ShuffleIndex[i:j]\n","\n","        X_Batch = np.copy(Clean_X_Train[Indices])\n","        Size = X_Batch.shape[0]\n","\n","        # Adversarial Data\n","        CW = CarliniWagnerL2(\n","            model_fn = Robust_CNN,\n","            y = np.repeat(Target_Encoding.reshape(-1,len(Target_Encoding)),Size,axis=0),\n","            targeted = True,\n","            batch_size = Batch_Size,\n","            clip_max = Max,\n","            clip_min = Min,\n","            max_iterations = nb_Iterations,\n","            confidence = Confidence,\n","            learning_rate = Learning_Rate\n","        )\n","\n","        X_Batch_Adv = CW.attack(X_Batch)\n","        \n","        Adv_X[Indices] = np.copy(X_Batch_Adv)\n","    \n","    X = np.append(Adv_X, Clean_X_Train, axis=0)\n","    y = np.append(Adv_y, Clean_y_Train, axis=0)\n","    # Train the Model\n","    TrainHistory = Robust_CNN.fit(X, y, epochs=1, batch_size=Batch_Size, verbose=1, shuffle=True)\n","\n","    # Loss and Accuracy\n","    Loss = np.mean(TrainHistory.history['loss'])\n","    Acc = np.mean(TrainHistory.history['accuracy'])\n","    \n","    # Updating Loss\n","    History['Loss'][epoch] = Loss\n","    History['Accuracy'][epoch] = Acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7GF_4HhOKzbx"},"source":["Plotting Loss"]},{"cell_type":"code","metadata":{"id":"mMaJGftZK4nq"},"source":["plt.figure()\n","\n","plt.subplot(1,2,1)\n","plt.grid()\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Loss\")\n","plt.plot(np.arange(Epochs), History['Loss'], label=\"Loss\")\n","plt.legend()\n","\n","plt.subplot(1,2,2)\n","plt.grid()\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Accuracy\")\n","plt.plot(np.arange(Epochs), History['Accuracy'], label=\"Accuracy\")\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OKMo-0PcTpl5"},"source":["Save Model"]},{"cell_type":"code","metadata":{"id":"vu03JE3lTrKy"},"source":["Robust_CNN.save(\"Robust_CNN\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OqfMVE3BTTmO"},"source":["### Evaluating Data"]},{"cell_type":"code","metadata":{"id":"vTMXSMGbTW8Q"},"source":["def EvaluateData(Model, X_Valid, y_Valid, SavePath, ValidBatchSize=32):\n","    Valid_SNR = np.arange(-20,20,2)\n","    Accuracy = []\n","\n","    print (\"Evaluating Model\")\n","    for snr in Valid_SNR:\n","        Pred_Labels = np.argmax(Model.predict(X_Valid[snr]),axis=1)\n","        True_Labels = np.argmax(y_Valid[snr],axis=1)\n","\n","        Acc = accuracy_score(True_Labels, Pred_Labels)\n","\n","        print (\"SNR:\", snr, \"Accuracy:\", Acc)\n","        Accuracy.append(Acc)\n","\n","    Accuracy = np.array(Accuracy)\n","\n","    plt.figure()\n","    plt.plot(Valid_SNR,Accuracy, color='blue')\n","    plt.scatter(Valid_SNR,Accuracy, color='red')\n","    plt.title(\"Accuracy vs SNR\")\n","    plt.xlabel(\"SNR\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.grid()\n","    plt.savefig(SavePath)\n","    plt.savefig(SavePath[:-3] + \".eps\")\n","    plt.show()\n","\n","Robust_CNN = tf.keras.models.load_model(\"Robust_CNN\")\n","EvaluateData(Robust_CNN, Clean_X_Valid, Clean_y_Valid, \"Robust_CNN_Accuracy.png\")"],"execution_count":null,"outputs":[]}]}